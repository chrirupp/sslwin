<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Self Supervised Learning: What is Next? - ECCV 2024</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            color: #333;
        }

        .header {
            background: url('images/background.jpg') no-repeat center center/cover;
            height: 300px;
            position: relative;
            text-align: center;
            color: white;
        }

        .header .overlay {
            background-color: rgba(0, 0, 0, 0.5);
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .header h1 {
            margin: 0;
            padding: 10px;
            font-size: 3em; /* Increased font size for more prominence */
        }

        .header h2 {
            margin: 0;
            padding: 10px;
            font-size: 2em;
        }

        .header h2 a {
            color: #fff;
            text-decoration: none;
        }

        .navbar {
            background-color: #333;
            overflow: hidden;
        }

        .navbar ul {
            list-style-type: none;
            padding: 0;
            margin: 0;
            display: flex;
            justify-content: center;
        }

        .navbar ul li {
            margin: 0;
        }

        .navbar ul li a {
            display: block;
            color: white;
            text-align: center;
            padding: 14px 20px;
            text-decoration: none;
        }

        .navbar ul li a:hover {
            background-color: #575757;
        }

        .content {
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }

        section {
            margin-bottom: 40px;
        }

        h2 {
            color: #444;
            text-align: center;
            margin-bottom: 20px;
        }

        .speakers-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr); /* Three columns */
            gap: 1.5rem; /* Space between grid items */
            justify-items: center; /* Center items in each grid cell */
        }

        .speaker {
            text-align: center;
            width: 200px;
        }

        .speaker img {
            border-radius: 60%;
            width: 180px;
            height: 180px;
            border: 2px solid #333;
        }

        .speaker a {
            color: #333;
            text-decoration: none;
        }

        .table-wrapper {
            width: 100%;
            overflow-x: auto;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            text-align: center;
        }

        td {
            padding: 10px;
        }

        .rounded-img-dark {
            border-radius: 50%;
            border: 2px solid #333;
        }

        .placeholder {
            background-color: gray;
            width: 200px;
            height: 200px;
            border-radius: 50%;
            display: inline-block;
        }

        footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 10px 0;
        }
    </style>
</head>
<body>
    <div class="header">
        <div class="overlay">
            <h1>Self Supervised Learning: What is Next?</h1>
            <h2><a href="https://eccv2024.ecva.net/">ECCV 2024, September 29th 9AM-1PM, Space 2 MiCo Milan</a></h2>
        </div>
    </div>

    <nav class="navbar">
        <ul>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#speakers">Speakers</a></li>
            <li><a href="#schedule">Schedule</a></li>
            <li><a href="#format">Posters Session</a></li>
            <li><a href="#info">Organizers</a></li>
            <li><a href="index2022.html">ECCV 2022</a></li>
        </ul>
    </nav>

    <div class="content">
        <section id="intro">
            <h2>Summary</h2>
            <p>Training robust visual models from unlabeled data is a long-standing problem, as human-provided annotations are often costly, error-prone, and incomplete. Consequently, self-supervised learning (SSL) has become an attractive research direction for learning generic visual representations useful for a wide range of downstream tasks such as classification and semantic segmentation. SSL operates on the principle of pretext tasks, self-generated challenges that encourage models to learn from the data's inherent structure. Initially, these tasks were relatively simplistic, such as predicting the rotation of an image or restoring its original colors. These early experiments laid the groundwork for more sophisticated techniques that extract deeper understandings from visual content through, e.g. contrastive learning or deep clustering.</p>
            <p>Although these methods have already outperformed supervised representations in numerous downstream tasks, the field continues to advance at an unprecedented pace, introducing many new techniques. Some of the directions are predictive architectures removing the need for augmentation, masked image modeling, auto-regressive approaches, leveraging the self-supervision signals in videos, and exploiting the representations of generative models.</p>
            <p>With so many new techniques flooding the field, it is important to pause and discuss how we can make optimal use of self-supervised representations in applications, as well as what are the remaining obstacles and possible approaches to tackle them. The workshop aims to give space to ask and discuss fundamental, longer-term questions with researchers leading this area. Key questions we aim to tackle include:</p>
            <ul>
                <li>What are the current bottlenecks in self-supervised learning?</li>
                <li>What is the role of SSL in the era of powerful image-text models?</li>
                <li>What can only or never be learned purely from self-supervision?</li>
                <li>What is the role of generative modeling for representation learning?</li>
                <li>Is SSL the new `pre-pretraining' paradigm, allowing to scale beyond coupled image-text data?</li>
                <li>What biases emerge in SSL models, and what are the implications?</li>
                <li>What is the role of multi-modal learning for robustness and understanding?</li>
                <li>What is the fundamental role of data augmentation and synthetic data?</li>
            </ul>
            <p>This is the third iteration of the SSL-WIN workshop. The workshop will be organized as a half-day event where a series of invited speakers will present their views on how the field needs to evolve in the coming years.</p>
        </section>

        <section id="speakers">
            <h2>Invited Speakers</h2>
            <div class="speakers-grid">
                <div class="speaker">
                    <img src="photos/asano.jpg" alt="Yuki M Asano">
                    <a href="https://yukimasano.github.io/">Yuki M. Asano<br>Univeristy of Amsterdam</a>
                </div>
                <div class="speaker">
                    <img src="photos/yutong.jpg" alt="Yutong Bai">
                    <a href="https://yutongbai.com/">Yutong Bai<br>UC Berkeley</a>
                </div>
                <div class="speaker">
                    <img src="photos/xinlei.jpeg" alt="Xinlei Chen">
                    <a href="https://xinleic.xyz/">Xinlei Chen<br>Meta AI</a>
                </div>
                <div class="speaker">
                    <img src="photos/olivierhenaff.jpg" alt="Olivier J. Hénaff">
                    <a href="https://www.olivierhenaff.com/">Olivier J. Hénaff<br>Google DeepMind</a>
                </div>
                <div class="speaker">
                    <img src="photos/misra.jpg" alt="Ishan Misra">
                    <a href="https://imisra.github.io/">Ishan Misra<br>Meta AI</a>
                </div>
                <div class="speaker">
                    <img src="photos/osimeoni.jpg" alt="Oriane Siméoni">
                    <a href="https://osimeoni.github.io/">Oriane Siméoni<br>valeo.ai</a>
                </div>

            </div>
        </section>

        <section id="schedule">
            <h2>Schedule</h2>
            <p>The workshop is a half-day event consisting of a series of invited talks on recent developments on self-supervised learning from leading experts in academia and industry, along with a poster session highlighting recent papers in the field.</p>
            <div class="schedule-container">
                <table class="schedule-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Speaker</th>
                            <th>Talk Title</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>09:00</td>
                            <td></td>
                            <td>Opening</td>
                        </tr>
                        <tr>
                            <td>09:00 - 09:30</td>
                            <td><a href="https://imisra.github.io/">Ishan Misra</td>
                            <td>What world priors do generative visual models learn?</td>
                        </tr>
                        <tr>
                            <td>09:30 - 10:00</td>
                            <td><a href="https://osimeoni.github.io/">Oriane Siméoni</td>
                            <td>From unsupervised object localization to open-vocabulary semantic segmentation
                            </td>
                        </tr>
                        <tr>
                            <td>10:00 - 10:30</td>
                            <td><a href="https://xinleic.xyz/">Xinlei Chen</td>
                            <td>tbd</td>
                        </tr>
                        <tr>
                            <td>10:30 - 11:20</td>
                            <td></td>
                            <td>Poster Session</td>
                        </tr>
                        <tr>
                            <td>11:20 -<br>11:55</td>
                            <td><a href="https://www.olivierhenaff.com/">Olivier J. Hénaff</td>
                            <td>Data curation is the next frontier of self-supervised learning</td>
                        </tr>
                        <tr>
                            <td>11:55 - 12:30</td>
                            <td><a href="https://yukimasano.github.io/">Yuki M. Asano</a></td>
                            <td>Vision Foundation Models (with academic compute)</td>
                        </tr>
                        <tr>
                            <td>12:30 - 13:00</td>
                            <td><a href="https://yutongbai.com/">Yutong Bai</a></td>
                            <td>Listening to the Data: Visual Learning from the Bottom Up</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>
        
        <style>
            #schedule {
                font-family: 'Arial', sans-serif;
                margin: 20px;
            }
        
            h2 {
                text-align: center;
                font-size: 2rem;
                color: #333;
            }
        
            .schedule-container {
                max-width: 1000px;
                margin: 0 auto;
            }
        
            .schedule-table {
                width: 100%;
                border-collapse: collapse;
                box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            }
        
            .schedule-table th, .schedule-table td {
                padding: 12px 15px;
                text-align: left;
                border-bottom: 1px solid #ddd;
            }
        
            .schedule-table th {
                background-color: #000000;
                color: white;
                font-weight: bold;
                text-transform: uppercase;
            }
        
            .schedule-table tr:nth-child(even) {
                background-color: #f9f9f9;
            }
        
            .schedule-table tr:hover {
                background-color: #f1f1f1;
            }
        
            .schedule-table td {
                font-size: 1rem;
            }
        
            .schedule-table td:nth-child(1) {
                font-weight: bold;
                color: #333;
            }
        </style>
        
        
        <section id="format">
            <h2 style="font-size: 2.5m;">Poster Session</h2>
            <p>
            List of accepted papers for presentation:
            <!DOCTYPE html>
<html lang="en">
    
    <ul>
        <!-- <li>
            <a href="https://arxiv.org/pdf/2401.14404">Deconstructing Denoising Diffusion Models for Self-Supervised Learning</a> - Presented by Xinlei Chen
        </li> -->
        <li>
            Poster 1: <a href="https://arxiv.org/abs/2312.02205">Disentangling the Effects of Data Augmentation and Format Transform in Self-Supervised Learning of Image Representations</a> - Presented by Philip Mansfield
        </li>
        <li>
            Poster 2: <a href="https://arxiv.org/abs/2408.14371">SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery</a> - Presented by Sarah Rastegar
        </li>                
        <li>
            Poster 3: <a href="https://arxiv.org/abs/2405.02771">MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning</a> - Presented by Vishal Nedungadi
        </li>
        <li>
            Poster 4: <a href="https://arxiv.org/abs/2408.02043">Deep Spectral Methods for Unsupervised Ultrasound Image Interpretation</a> - Presented by Yordanka Velikova
        </li>
        <li>
            Poster 5: <a href="https://arxiv.org/pdf/2312.01187">SASSL: Leveraging Neural Style Transfer for Improved Self-Supervised Learning</a> - Presented by Philip Mansfield
        </li>
        <li>
            Poster 6: <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Kowal_Understanding_Video_Transformers_via_Universal_Concept_Discovery_CVPR_2024_paper.html">VTCD: Understanding Video Transformers via Universal Concept Discovery</a> - Presented by Matthew Kowal
        </li>
        <li>
            Poster 7: <a href="https://arxiv.org/abs/2403.17823">Efficient Image Pre-Training with Siamese Cropped Masked Autoencoders</a> - Presented by Renaud Vandeghen
        </li>
        Poster 8: <a href="https://arxiv.org/abs/2407.13036">ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders</a> - Presented by Carlos Hinojosa
        </li>
        <li>
        Poster 9: <a href="https://melika.xyz/data/paper.pdf">PART: Self-supervised Pretraining with Pairwise Relative Translations</a> - Presented by Melika Ayouhi
        </li>
        <li>
        Poster 10: <a href="https://arxiv.org/abs/2407.15447">SIGMA: Sinkhorn-Guided Masked Video Modeling</a> - Presented by Mohammadreza Salehi
        </li>

        <li>
        Poster 11: <a href="https://arxiv.org/abs/2408.05088">UNIC: Universal Classification Models via Multi-teacher Distillation</a> - Presented by Mert Bulent Sariyildiz
        </li>
        <li>
            Poster 12: <a href="https://arxiv.org/abs/2310.02903">FroSSL: Frobenius Norm Minimization for Efficient Multiview Self-Supervised Learning
            </a> - Oscar Skean
        </li>
        </ul>


            </p>
        </section>

        <section id="info" class="main special">
            <header class="major">
                <h2>Organizers</h2>
            </header>
            <div class="table-wrapper" style="width:100%">
                <table cellpadding="0" cellspacing="0">
                    <tr>
                        <td>
                            <img class="rounded-img-dark" height="125px" src="photos/mdorkenwald.jpg">
                            <br>
                            <a href="https://mdorkenwald.com/">Michael Dorkenwald<br>University of Amsterdam</a>
                        </td>
                        <td>
                            <img class="rounded-img-dark" height="125px" src="photos/mert.png">
                            <br>
                            <a href="https://mbsariyildiz.github.io/">Mert Bulent Sariyildiz<br>NAVER LABS Europe</a>
                        </td>
                        <td>
                            <img class="rounded-img-dark" height="125px" src="photos/rupprecht.jpg">
                            <br>
                            <a href="http://chrirupp.github.io">Christian Rupprecht<br>University of Oxford</a>
                        </td>
                        <td>
                            <img class="rounded-img-dark" height="125px" src="photos/Hilde.jpg">
                            <br>
                            <a href="https://hildekuehne.github.io/">Hilde Kuehne<br>University of Bonn</a>
                        </td>
                        <td>
                            <img class="rounded-img-dark" height="125px" src="photos/sbelongie.png">
                            <br>
                            <a href="https://sergebelongie.github.io/">Serge Belongie<br>University of Copenhagen</a>
                        </td>
                    </tr>
                </table>
            </div>
        </section>
    </div>

    <footer>
        <p>&copy; 2024 Self Supervised Learning: What is Next? - ECCV 2024. All rights reserved.</p>
    </footer>
</body>
</html>
